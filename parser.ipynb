{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importovanie knižníc, funkcie na úpravu dátumu a nastavenie adresy pre ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import calendar\n",
    "import glob\n",
    "from elasticsearch import Elasticsearch\n",
    "import datetime\n",
    "abbr_to_num = {name: num for num, name in enumerate(calendar.month_abbr) if num}\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Analyzers/analyzer.txt', 'r') as myfile:\n",
    "    analyzer=myfile.read()\n",
    "es.indices.create(index='goodreads-test', ignore=400, body=analyzer)\n",
    "\n",
    "with open('Analyzers/french.txt', 'r') as myfile:\n",
    "    analyzer_f=myfile.read()\n",
    "es.indices.create(index='goodreads-test-f', ignore=400, body=analyzer_f)\n",
    "    \n",
    "with open('Analyzers/german.txt', 'r') as myfile:\n",
    "    analyzer_g=myfile.read()\n",
    "es.indices.create(index='goodreads-test-g', ignore=400, body=analyzer_g)\n",
    "    \n",
    "with open('Analyzers/spanish.txt', 'r') as myfile:\n",
    "    analyzer_s=myfile.read()\n",
    "es.indices.create(index='goodreads-test-s', ignore=400, body=analyzer_s)\n",
    "\n",
    "\n",
    "with open('mapper/mapping.txt', 'r') as myfile:\n",
    "    mapping=myfile.read()\n",
    "with open('mapper/mapping_f.txt', 'r') as myfile:\n",
    "    mapping_f=myfile.read()\n",
    "with open('mapper/mapping_g.txt', 'r') as myfile:\n",
    "    mapping_g=myfile.read()\n",
    "with open('mapper/mapping_s.txt', 'r') as myfile:\n",
    "    mapping_s=myfile.read()\n",
    "\n",
    "    \n",
    "es.indices.put_mapping(index='goodreads-test',body=mapping)\n",
    "es.indices.put_mapping(index='goodreads-test-f',body=mapping_f)\n",
    "es.indices.put_mapping(index='goodreads-test-s',body=mapping_s)\n",
    "es.indices.put_mapping(index='goodreads-test-g',body=mapping_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia na extrahovanie informácií z HTML stánky spolu s ošetrením, ak sa daný údaj na stránke nenachádza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_langs(html):\n",
    "#     print(html)\n",
    "#     try\n",
    "\n",
    "    try:\n",
    "        lang = re.search('(itemprop=\\\"inLanguage\\\">)(([a-z]|[A-Z]).*)\\<',html).group(2)\n",
    "        print(lang)\n",
    "    except: \n",
    "        lang = \"Undef\"\n",
    "    x = {\n",
    "      \"lang\": lang}\n",
    "    return json.dumps(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html):\n",
    "#     print(html)\n",
    "#     try\n",
    "\n",
    "    try:\n",
    "        lang = re.search('(itemprop=\\\"inLanguage\\\">)(([a-z]|[A-Z]).*)\\<',html).group(2)\n",
    "#         print(lang)\n",
    "    except: \n",
    "        lang = \"Undef\"\n",
    "    try:\n",
    "        ident = re.search('\\/book\\/show\\/([0-9]*)',html).group(1)\n",
    "#         print(ident)\n",
    "    except: \n",
    "        ident = None\n",
    "    try:\n",
    "        description = re.search('id=\\\"description\\\"(.*\\n){3}.*\\\"\\>(.*)\\<\\/',html).group(1)\n",
    "#         print(description)\n",
    "    except: \n",
    "        try:\n",
    "            description = re.search('id=\\\"description\\\"(.*\\n){1}.*\\\"\\>(.*)\\<\\/',html).group(2)\n",
    "        except:\n",
    "            description = None\n",
    "    try:\n",
    "#         description = description.replace('<[^>]*>', ' ')\n",
    "        description = re.sub('<[^>]*>', \" \", description)\n",
    "    except: \n",
    "        description = None\n",
    "    try:\n",
    "        name = re.search('\\\"bookTitle.*\\n\\s*(.*)',html).group(1)\n",
    "#         name = re.search('(?<=(Original Title<\\/div>\\n)).*(?=\\ \\<)',html)\n",
    "#         print(name)\n",
    "    except: \n",
    "        name = None\n",
    "#         print(\"sas\")\n",
    "    try:\n",
    "        isbn = re.search('(?<=(ISBN<\\/div>\\n)).*\\n\\s*(.*)',html).group(2)\n",
    "    except: \n",
    "        isbn = None\n",
    "    try:\n",
    "        isbn13 = re.search('(?<=(ISBN<\\/div>\\n)).*\\n.*\\n.*((?<=\\>).*)(?=\\<span)[^0-9]*([0-9]+)',html).group(3)\n",
    "    except: \n",
    "        isbn13 = None\n",
    "    try:\n",
    "        series = re.search('(?<=(Series<\\/div>\\n))((\\s*\\<d|\\s*\\<a).*\\n){0,10}\\s*<\\/div>',html).group()\n",
    "    except: \n",
    "        series = None\n",
    "    try:\n",
    "        series = re.findall('\\>([a-zA-Z0-9#\\ -]*)\\<\\/a',series)\n",
    "    except: \n",
    "        series = None\n",
    "    try:\n",
    "        characters = re.findall('\\/characters.{1,40}\"\\>([a-zA-z0-9\\ ]*)\\<',html)\n",
    "    except: \n",
    "        characters = None\n",
    "#     obj= make_BookObj(ident, name, isbn, isbn13, series, characters)\n",
    "#     Object.assign(obj, characters)\n",
    "\n",
    "#     return obj\n",
    "#     print(create_json(ident, name, isbn, isbn13, series, description, characters))\n",
    "    return create_json(ident, lang , name, isbn, isbn13, series, description, characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookObj(object):\n",
    "    ident: 0\n",
    "    name: None\n",
    "    isbn: None\n",
    "    isbn13: None\n",
    "    series: None\n",
    "    lang: None\n",
    "#          description: description\n",
    "    characters: None\n",
    "\n",
    "    def __init__(self, lang, ident, name, isbn, isbn13, series, characters):\n",
    "        self.ident: ident\n",
    "        self.name: name\n",
    "        self.isbn: isbn\n",
    "        self.isbn13: isbn13\n",
    "        self.series: series\n",
    "        self.lang: lang\n",
    "#          self.description: description\n",
    "        self.characters: characters\n",
    "\n",
    "def make_BookObj(ident, name, isbn, isbn13, series, characters):\n",
    "    book = BookObj(ident, name, isbn, isbn13, series, characters)\n",
    "    return book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia zo vstupných údajov vytvorí JSON formát, a vlozi ho do elastic search databazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(ident, lang, name, isbn, isbn13, series, description, characters):\n",
    "    x = {\n",
    "      \"id\": ident,\n",
    "      \"lang\": lang,\n",
    "      \"name\": name,\n",
    "      \"isbn\": isbn,\n",
    "      \"isbn13\": isbn13,\n",
    "      \"series\": series,\n",
    "      \"description\": description,\n",
    "      \"characters\": characters\n",
    "    }\n",
    "    y = json.dumps(x)\n",
    "    global es\n",
    "    page_id=0\n",
    "    page_id += 1\n",
    "    return y\n",
    "#     print(json.dumps(json.loads(y), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spracovanie všetkých HMTL súborov uložených v adresári."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n",
      "5250\n",
      "5500\n",
      "5750\n",
      "6000\n",
      "6250\n",
      "6500\n",
      "6750\n",
      "7000\n",
      "7250\n",
      "7500\n",
      "7750\n",
      "8000\n",
      "8250\n",
      "8500\n",
      "8750\n",
      "9000\n",
      "9250\n",
      "9500\n",
      "9750\n",
      "10000\n",
      "10250\n",
      "10500\n",
      "10750\n",
      "11000\n",
      "11250\n",
      "11500\n",
      "11750\n",
      "12000\n",
      "12250\n",
      "12500\n",
      "12750\n",
      "13000\n",
      "13250\n",
      "13500\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(\"D:/School/VINF/Data\")\n",
    "# folders = os.listdir(\"D:/School/VINF/DATA-TEST\")\n",
    "arr = []\n",
    "arr_g = []\n",
    "arr_s = []\n",
    "arr_f = []\n",
    "count = 0\n",
    "# langs= []\n",
    "for folder in folders:\n",
    "    count=count+1\n",
    "    if count% 250 == 0:\n",
    "        print(count)\n",
    "    book = {}\n",
    "    book_g = {}\n",
    "    book_s = {}\n",
    "    book_f = {}\n",
    "    arr_g.clear()\n",
    "    arr_s.clear()\n",
    "    arr_f.clear()\n",
    "    arr.clear()\n",
    "    book['book'] = folder\n",
    "    book_g['book'] = folder\n",
    "    book_s['book'] = folder\n",
    "    book_f['book'] = folder\n",
    "    files = glob.glob(\"D:/School/VINF/Data/\"+folder+\"/*.html\")\n",
    "#     files = glob.glob(\"D:/School/VINF/DATA-TEST/\"+folder+\"/*.html\")\n",
    "    for file in files:\n",
    "        html = open(file,encoding=\"utf8\")    \n",
    "        soup = html.read()\n",
    "#         print(soup)\n",
    "        obj = (json.loads(parse_html(soup)))\n",
    "#         lnagsObj = (json.loads(parse_langs(soup)))\n",
    "        identity= re.search('([0-9]*)\\.',file).group(1)\n",
    "        obj['id'] = identity\n",
    "\n",
    "        arr.append(obj)\n",
    "        if obj['lang'] == \"German\":\n",
    "            arr_g.append(obj)\n",
    "        elif obj['lang'] == \"Spanish\":\n",
    "            arr_s.append(obj)\n",
    "        elif obj['lang'] == \"French\":\n",
    "            arr_f.append(obj)\n",
    "        \n",
    "#         langs.append(lnagsObj)\n",
    "\n",
    "        if arr:\n",
    "            book['editions']=arr\n",
    "        if arr_g:\n",
    "            book_g['editions']=arr_g\n",
    "        if arr_s:\n",
    "            book_s['editions']=arr_s\n",
    "        if arr_f:\n",
    "            book_f['editions']=arr_f\n",
    "#         print(arr)\n",
    "\n",
    "    try:\n",
    "        book['editions']\n",
    "        jsonObj=json.dumps(book, indent=4, )\n",
    "        es.index(index='goodreads-test', id=identity, body=jsonObj)\n",
    "#         print('EEE')\n",
    "    except:\n",
    "        book={}\n",
    "    try:\n",
    "        book_f['editions']\n",
    "        jsonObj_f=json.dumps(book_f, indent=4, )\n",
    "        es.index(index='goodreads-test-f', id=identity, body=jsonObj_f)\n",
    "#         print('FFF')\n",
    "    except:\n",
    "        book_f={}\n",
    "    try:\n",
    "        book_s['editions']\n",
    "        jsonObj_s=json.dumps(book_s, indent=4, )\n",
    "        es.index(index='goodreads-test-s', id=identity, body=jsonObj_s)\n",
    "#         print('SSS')\n",
    "    except:\n",
    "        book_s={}\n",
    "    try:\n",
    "        book_g['editions']\n",
    "#         print('GGG')\n",
    "        jsonObj_g=json.dumps(book_g, indent=4, )\n",
    "        es.index(index='goodreads-test-g', id=identity, body=jsonObj_g)\n",
    "    except:\n",
    "        book_g={}\n",
    "        \n",
    "#     es.index(index='goodreads-test', id=ident, body=jsonObj)\n",
    "#     print(jsonObj)\n",
    "#     print(\"  \")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Arabic', 'Chinese', 'Danish', 'Dutch', 'English',\n",
       "        'English, Middle (1100-1500)', 'French', 'German',\n",
       "        'Greek, Ancient (to 1453)', 'Greek, Modern (1453-)', 'Italian',\n",
       "        'Japanese', 'Ladino', 'Latin', 'Multiple languages',\n",
       "        'Munda languages', 'Norwegian', 'Portuguese', 'Russian', 'Serbian',\n",
       "        'Spanish', 'Turkish', 'Undef'], dtype='<U27'),\n",
       " array([    3,    12,     2,     3, 14080,     2,   148,   182,    10,\n",
       "            2,    12,    44,     1,     4,    21,     1,     1,    11,\n",
       "            8,     1,   394,     1,  1956], dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(list(map(lambda x: x['lang'], langs))), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
